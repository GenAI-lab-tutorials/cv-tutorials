{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the COCO8 dataset for 100 epochs\n",
    "train_results = model.train(\n",
    "    data=\"coco8.yaml\",  # Path to dataset configuration file\n",
    "    epochs=100,  # Number of training epochs\n",
    "    imgsz=640,  # Image size for training\n",
    "    device=\"cpu\",  # Device to run on (e.g., 'cpu', 0, [0,1,2,3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the validation set\n",
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/shravan/documents/deeplearning/gen_ai/genai_lab/cv-tutorials/datasets/coco8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load model\n",
    "# model = YOLO(\"yolov8n.pt\")  # or your custom .pt model\n",
    "\n",
    "val_dir = Path(\"/home/shravan/documents/deeplearning/gen_ai/genai_lab/cv-tutorials/datasets/coco8/images/val\")\n",
    "image_paths = sorted(val_dir.glob(\"*.jpg\"))\n",
    "\n",
    "for img_path in image_paths:\n",
    "    results = model(str(img_path))\n",
    "    \n",
    "    # Get image with boxes\n",
    "    pred_img = results[0].plot()\n",
    "    pred_img_rgb = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display in notebook\n",
    "    plt.imshow(pred_img_rgb)\n",
    "    plt.title(f\"Predictions: {img_path.name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define remote image or video URL\n",
    "source = \"https://ultralytics.com/images/bus.jpg\"\n",
    "source = \"https://www.team-bhp.com/forum/attachments/super-cars-imports-india/2037462d1596381376-111-garage-tasteful-car-collection-hyderabad-mustang-mach-1.jpg\"\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source)  # list of Results objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get plotted result\n",
    "im = results[0].plot()  # returns BGR image with boxes drawn\n",
    "\n",
    "# Convert to RGB and show\n",
    "plt.imshow(im[..., ::-1])\n",
    "plt.axis('off')\n",
    "plt.title(\"Predictions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "model.export(format=\"onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Rerun inference or continue from earlier results\n",
    "for result in results:  # each frame/image\n",
    "    img = result.orig_img.copy()  # original BGR image\n",
    "    boxes = result.boxes  # boxes.xyxy, boxes.cls, boxes.conf\n",
    "\n",
    "    if boxes is None or boxes.xyxy.shape[0] == 0:\n",
    "        print(\"No detections.\")\n",
    "        continue\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes.xyxy[i].cpu().numpy().astype(int)  # [x1, y1, x2, y2]\n",
    "        cls = int(boxes.cls[i].cpu().item())\n",
    "        conf = float(boxes.conf[i].cpu().item())\n",
    "        label = result.names[cls]  # class name\n",
    "\n",
    "        # Crop box from image\n",
    "        x1, y1, x2, y2 = box\n",
    "        cropped = img[y1:y2, x1:x2]  # BGR crop\n",
    "\n",
    "        # Plot using matplotlib\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"{label} ({conf:.2f})\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        # Optional: Wait for key press if looping through video\n",
    "        input(\"Press Enter to view next box...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_lab",
   "language": "python",
   "name": "genai_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
