{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 🧠 01 — Image Basics with OpenCV and NumPy\n",
    "\n",
    "> *\"An image is not what you **see**. It's what the computer **reads**.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 🔍 What *is* an Image?\n",
    "\n",
    "Before we dive into code, let’s understand what a digital image is:\n",
    "\n",
    "* 📷 A **grayscale image** is a 2D array of pixel intensity values ranging from **0 to 255**.\n",
    "* 🌈 A **color image (RGB)** is a 3D array with 3 channels: **Red**, **Green**, and **Blue**.\n",
    "\n",
    "Let’s visualize this using OpenCV and Matplotlib.\n",
    "\n",
    "---\n",
    "\n",
    "## 📥 Download a Sample Image\n",
    "\n",
    "We’ll use the classic **Lena image** to explore image structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg -O sample.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 📦 Load and Display an RGB Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image (OpenCV loads in BGR format)\n",
    "image = cv2.imread('sample.jpg')\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# Convert to RGB for correct display in matplotlib\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Show image\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Original RGB Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "> 💡 **Note:** OpenCV reads images in **BGR**, not RGB. Convert using `cv2.cvtColor()` before visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 🌑 Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title(\"Grayscale Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 📊 Pixel Intensity Distribution\n",
    "\n",
    "Understanding histogram distributions helps analyze brightness, contrast, and exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gray.ravel(), bins=256, range=(0, 256))\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Pixel Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 🧮 Access Pixel-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w) = image.shape[:2]\n",
    "center_pixel = image[h // 2, w // 2]  # BGR format\n",
    "print(f\"Center pixel (BGR): {center_pixel}\")\n",
    "\n",
    "# 10x10 patch around the center\n",
    "patch = image[h//2-5:h//2+5, w//2-5:w//2+5]\n",
    "print(\"10x10 pixel patch:\\n\", patch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## ✂️ Resize and Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(image_rgb, (128, 128))\n",
    "flipped = cv2.flip(image_rgb, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1); plt.imshow(resized); plt.title(\"Resized\")\n",
    "plt.subplot(1, 2, 2); plt.imshow(flipped); plt.title(\"Flipped Horizontally\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 🔍 View Individual Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = cv2.split(image_rgb)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1); plt.imshow(r, cmap='Reds'); plt.title(\"Red Channel\")\n",
    "plt.subplot(1, 3, 2); plt.imshow(g, cmap='Greens'); plt.title(\"Green Channel\")\n",
    "plt.subplot(1, 3, 3); plt.imshow(b, cmap='Blues'); plt.title(\"Blue Channel\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 🧪 Mini Challenge: Remove the Red Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no_red = image_rgb.copy()\n",
    "image_no_red[:, :, 0] = 0  # Red channel (index 0 in RGB)\n",
    "\n",
    "plt.imshow(image_no_red)\n",
    "plt.title(\"Red Channel Removed\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "* ✅ Images are arrays — grayscale is 2D, RGB is 3D.\n",
    "* 🌀 OpenCV reads in **BGR**, not RGB.\n",
    "* 🔬 You can extract channels, resize, flip, and inspect histograms.\n",
    "* 🧬 NumPy gives full pixel-level control.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 📚 Want to Learn More?\n",
    "\n",
    "* 📘 [PyImageSearch – OpenCV Basics](https://pyimagesearch.com/category/opencv/)\n",
    "* 📘 [CS231n – Digital Image Fundamentals](https://cs231n.github.io/)\n",
    "* 📘 [OpenCV Documentation](https://docs.opencv.org/4.x/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 🧪 Coming Up Next\n",
    "\n",
    "> In the next notebook, we’ll explore **color spaces** like HSV and LAB — and understand why they matter for real-world applications like segmentation and filtering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_lab",
   "language": "python",
   "name": "genai_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
